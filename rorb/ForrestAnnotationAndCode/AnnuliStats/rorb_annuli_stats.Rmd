---
title: "Annuli Stats followed by PCA on RORB"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    fig_height: 10
    fig_width: 10
    highlight: pygments
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 2
---
```{r knitOPTS, include=FALSE}
knitr::opts_chunk$set(cache = FALSE, dev = "png")
knitr::opts_chunk$set(engine.path = 
  list( 
      python = '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'
      )
)
```

```{r render, eval=FALSE, echo=FALSE}
require(rmarkdown)
require(knitr)
rmarkdown::render("rorb_annuli_stats.Rmd"); system("open rorb_annuli_stats.html -a /Applications/Chrome.app")
```

```{r setup,include=FALSE,results='asis',message=FALSE,warning=FALSE, echo = FALSE}
# Library calls here.
require(rmarkdown)
require(NMF)
require(knitr)
require(MASS)
require(doMC)
require(foreach)
require(iterators)
require(scales)
require(raster)
require(mgc)
require(mvtnorm)
require(googlesheets)
registerDoMC(8)
suppressMessages(require(meda))
```


# PCA on annuli stats using $L_1$ Norm

```{r start, eval = TRUE}
naL1 <- fread("rorb_annuli_stats_GoogleDoc.csv", header = FALSE)
cnames <- colnames(naL1)
meta <- fread("GoogleDocData.csv")
loc <- fread("GoogleDocData.csv")[, 1:3]
ids <- as.data.frame(read.csv("GoogleDocData.csv")[, 4])
colnames(ids) <- 'id'

ccolL1 <- c('blue', 'blue', 'blue', 'red', 'red', 'red', 'black', 'black', 'green', 'green', 'black', 'green')
ccolL1 <-  rep(ccolL1, each = 15)

CHAN_NAMES <- rep(c('DAPI1', 'DAPI2', 'DAPI3', 'GABA', 'GAD2', 'Gephyrin', 'GluN1', 'MBP', 'PSD95', 'synapsin', 'TdTomato', 'VGlut1'), each = 15)

colnames(naL1) <- paste0(CHAN_NAMES,"_", sprintf("%02d",1:15))
```

```{r}
snaL1 <- scale(naL1, center = TRUE, scale = TRUE)
pc1 <- princomp(snaL1)
gaba <- as.factor(meta$gaba)
```

## LDA and QDA

Next, applying LDA and QDA iterating on the number of PCA dimension
included. 

```{r lda-gabaL1}
y <- as.factor(gaba)

ldaL1 <- foreach(di = 1:ncol(snaL1)) %dopar% {
           x <- as.data.frame(pc1$scores[, 1:di])
           ldatmp <- lda(y ~ ., data = x, CV = FALSE)
           ldatmp
}

qdaL1 <- foreach(di = 1:ncol(snaL1)) %dopar% {
           x <- as.data.frame(pc1$scores[, 1:di])
           qdatmp <- 
             tryCatch(qda(y ~ ., data = x, CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfL1 <- foreach(di = 1:ncol(snaL1)) %dopar% {
           tmpdat <- data.table(gaba = gaba, pc1$scores[, 1:di])
           rftmp <- randomForest(gaba ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

#saveRDS(list(ldaL1, qdaL1, rfL1), file = "models_lda_qda_rf.rdat")

ll <- sapply(ldaL1, function(x) sum(predict(x)$class != gaba)/length(gaba))
ql <- sapply(qdaL1[!is.na(qdaL1)], function(x) sum(predict(x)$class != gaba)/length(gaba))
rl <- sapply(rfL1,   function(x) sum(predict(x) != gaba)/length(gaba))
```

```{r plot-itL1}
plot(x = 1:ncol(pc1$scores), y = seq(0,max(ll,ql,rl),length = ncol(pc1$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(ll, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(ql, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(rl, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(gaba == 1)/length(gaba), col = 'magenta', lty=4)
text(which.min(ql),0, label = paste("qda", min(round(ql, 3))), col = 'orange')
text(which.min(ll), 0, label = paste("lda", min(round(ll,3))), col = 'blue')
text(which.min(rl), 0, label = paste("rf", min(round(rl,3))), col = 'darkgreen')
text(ncol(snaL1)/4, chance, label = "chance", col = 'magenta', pos = 3)
```

## On permutations of the labels

```{r lda-gabaL1perm}
set.seed(1030)
yp <- sample(as.factor(gaba))

ldaL1prem <- foreach(di = 1:ncol(snaL1)) %dopar% {
           x <- as.data.frame(pc1$scores[, 1:di])
           ldatmp <- lda(yp ~ ., data = x, CV = FALSE)
           ldatmp
}

qdaL1prem <- foreach(di = 1:ncol(snaL1)) %dopar% {
           x <- as.data.frame(pc1$scores[, 1:di])
           qdatmp <- 
             tryCatch(qda(yp ~ ., data = x, CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfL1prem <- foreach(di = 1:ncol(snaL1)) %dopar% {
           tmpdat <- data.table(yp = yp, pc1$scores[, 1:di])
           rftmp <- randomForest(yp ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

#saveRDS(list(ldaL1prem, qdaL1prem, rfL1prem), file = "models_lda_qda_rf.rdat")

llperm <- sapply(ldaL1prem, function(x) sum(predict(x)$class != yp)/length(yp))
qlperm <- sapply(qdaL1prem[!is.na(qdaL1prem)], function(x) sum(predict(x)$class != yp)/length(yp))
rlperm <- sapply(rfL1prem,   function(x) sum(predict(x) != yp)/length(yp))
```

```{r plot-itL1perm}
plot(x = 1:ncol(pc1$scores), y = seq(0,max(llperm,qlperm,rlperm),length = ncol(pc1$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(llperm, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(qlperm, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(rlperm, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(yp == 1)/length(yp), col = 'magenta', lty=4)
text(which.min(qlperm),0, label = paste("qda", min(round(qlperm, 3))), col = 'orange')
text(which.min(llperm), 0, label = paste("lda",min(round(llperm,3))), col = 'blue')
text(which.min(rlperm), 0, label = paste("rf", min(round(rlperm,3))), col = 'darkgreen')
text(ncol(snaL1)/4, chance, label = "chance", col = 'magenta', pos = 3)
title("On permuted labels")
```


# Synthetic data from the $L_1$ 

```{r synL1}
mu0 <- colMeans(naL1[gaba == 0,])
mu1 <- colMeans(naL1[gaba == 1,])

sigma0 <- cov(naL1[gaba == 0,])
sigma1 <- cov(naL1[gaba == 1,])


tind <- grep("GABA", names(naL1))
dens12 <- densityMclust(naL1)

plot(dens12)


plot(medacor(naL1[gaba == 0,], ccol = ccolL1)); title("Correlation plot of gaba == 0")
plot(medacor(naL1[gaba == 1,], ccol = ccolL1)); title("Correlation plot of gaba == 1")

set.seed(317)
simGaba <- sort(rbinom(1e3, size = 1, prob = sum(gaba == 1)/length(gaba)))

simDat <- 
  as.data.table(
    rbind(rmvnorm(sum(simGaba == 0), mean = mu0, sigma = sigma0),
          rmvnorm(sum(simGaba == 1), mean = mu1, sigma = sigma1))
    )

plot(naL1$GABA_01)
plot(density(naL1$GABA_01))

fit <- density(naL1$GABA_01)

N <- 1e6
mEst <- sample(naL1$GABA_01, size = N, replace = TRUE)

x.new <- rnorm(N, mEst, fit$bw)

plot(fit)
lines(density(x.new), col = 'blue')
x.new
```

```{r kde-samp}
set.seed(3171)
N <- 1e4

kdeGaba <- sort(rbinom(N, size = 1, prob = sum(gaba == 1)/length(gaba)))
N0 <- sum(kdeGaba == 0)
N1 <- sum(kdeGaba == 1)

kdeG0 <- 
  foreach(ci = iter(as.matrix(naL1[gaba == 0,]), by = 'column'), .combine = 'cbind') %dopar% {
    fit <- density(ci)
    mest <- sample(ci, size = N0, replace = TRUE)
    rnorm(N0, mest, sd = fit$bw)
  }

kdeG1 <- 
  foreach(ci = iter(as.matrix(naL1[gaba == 1,]), by = 'column'), .combine = 'cbind') %dopar% {
    fit <- density(ci)
    mest <- sample(ci, size = N1, replace = TRUE)
    rnorm(N1, mest, sd = fit$bw)
  }

kdeData <- data.table(rbind(kdeG0, kdeG1))
plot(mlocation(kdeData))
plot(mlocation(naL1))

kdepc <- princomp(scale(kdeData, center = TRUE, scale = TRUE))
```


```{r synkdeLDA-QDA-RF}
ykde <- as.factor(kdeGaba)

seq1 <- seq(1, ncol(kdeData), length = 4)

ldaL1kde <- foreach(di = seq1) %dopar% {
           x <- as.data.frame(kdepc$scores[, 1:di])
           ldatmp <- lda(ykde ~ ., data = x, CV = FALSE)
           ldatmp
}

qdaL1kde <- foreach(di = seq1) %dopar% {
           x <- as.data.frame(kdepc$scores[, 1:di])
           qdatmp <- 
             tryCatch(qda(ykde ~ ., data = x, CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfL1kde <- foreach(di = seq1) %dopar% {
           tmpdat <- data.table(ykde = ykde, kdepc$scores[, 1:di])
           rftmp <- randomForest(ykde ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

#saveRDS(list(ldaL1prem, qdaL1prem, rfL1prem), file = "models_lda_qda_rf.rdat")

llkde <- sapply(ldaL1kde, function(x) sum(predict(x)$class != ykde)/length(ykde))
qlkde <- sapply(qdaL1kde[!is.na(qdaL1kde)], function(x) sum(predict(x)$class != ykde)/length(ykde))
rlkde <- sapply(rfL1kde,   function(x) sum(predict(x) != ykde)/length(ykde))
```

```{r plot-itL1perm}
plot(x = 1:ncol(kdepc$scores), y = seq(0,max(llkde,qlkde, chance),length = ncol(kdepc$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(seq1, y = llkde, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(seq1, y = qlkde, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(seq1, y = rlkde, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(ykde == 1)/length(ykde), col = 'magenta', lty=4)
text(which.min(qlkde),0, label = paste("qda", min(round(qlkde, 3))), col = 'orange')
text(which.min(llkde), 0, label = paste("lda",min(round(llkde,3))), col = 'blue')
text(which.min(rlkde), 0, label = paste("rf", min(round(rlkde,3))), col = 'darkgreen')
text(ncol(kdeData)/4, chance, label = "chance", col = 'magenta', pos = 3)
title("On synthetic data from KDE")
```

```{r compare, eval = FALSE}
plot(mlocation(naL1[gaba ==1,], ccol = ccolL1))
dev.new()
dev.set(dev.prev())
dev.set(dev.next())
plot(mlocation(kdeData[kdeGaba ==1,], ccol = ccolL1))
```



# PCA on annuli stats using weighted $L_1$ Norm

```{r startW, eval = TRUE}
naL1W <- fread("rorb_annuli_stats_GoogleDocL1W.csv", header = FALSE)

ccolL1 <- c('blue', 'blue', 'blue', 'red', 'red', 'red', 'black', 'black', 'green', 'green', 'black', 'green')
ccolL1 <-  rep(ccolL1, each = 15)

CHAN_NAMES <- rep(c('DAPI1', 'DAPI2', 'DAPI3', 'GABA', 'GAD2', 'Gephyrin', 'GluN1', 'MBP', 'PSD95', 'synapsin', 'TdTomato', 'VGlut1'), each = 15)

colnames(naL1W) <- paste0(CHAN_NAMES,"_", sprintf("%02d",1:15))
```

```{r}
snaL1W <- scale(naL1W, center = TRUE, scale = TRUE)
pc1W <- princomp(snaL1W)
```

## LDA and QDA on weighted $L_1$

```{r lda-gabaL1W}
ldaL1W <- foreach(di = 1:ncol(snaL1W)) %dopar% {
           x <- as.data.frame(pc1W$scores[, 1:di])
           ldatmp <- lda(y ~ ., data = x, CV = FALSE)
           ldatmp
}

qdaL1W <- foreach(di = 1:ncol(snaL1W)) %dopar% {
           x <- as.data.frame(pc1W$scores[, 1:di])
           qdatmp <- 
             tryCatch(qda(y ~ ., data = x, CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfL1W <- foreach(di = 1:ncol(snaL1W)) %dopar% {
           tmpdat <- data.table(gaba = gaba, pc1W$scores[, 1:di])
           rftmp <- randomForest(gaba ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

#saveRDS(list(ldaL1W, qdaL1W, rfL1W), file = "models_lda_qda_rf.rdat")

llW <- sapply(ldaL1W, function(x) sum(predict(x)$class != gaba)/length(gaba))
qlW <- sapply(qdaL1W[!is.na(qdaL1W)], function(x) sum(predict(x)$class != gaba)/length(gaba))
rlW <- sapply(rfL1W,   function(x) sum(predict(x) != gaba)/length(gaba))
```

```{r plot-itL1W}
plot(x = 1:ncol(pc1W$scores), y = seq(0,max(llW,qlW,rlW),length = ncol(pc1W$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(llW, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(qlW, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(rlW, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(gaba == 1)/length(gaba), col = 'magenta', lty=4)
text(which.min(qlW),0, label = paste("qda", min(round(qlW, 3))), col = 'orange')
text(which.min(llW), 0, label = paste("lda",min(round(llW,3))), col = 'blue')
text(which.min(rlW), 0, label = paste("rf", min(round(rlW,3))), col = 'darkgreen')
text(ncol(snaL1W)/4, chance, label = "chance", col = 'magenta', pos = 3)
title("Run on weighted L_1 data")
```









## PCA on annuli stats using $L_{\infty}$ Norm

```{r startInf, eval = TRUE}
naInf <- fread("rorb_annuli_stats_GoogleDocInf.csv", header = FALSE)
cnames <- colnames(naInf)
meta <- fread("GoogleDocData.csv")
loc <- fread("GoogleDocData.csv")[, 1:3]
ids <- as.data.frame(read.csv("GoogleDocData.csv")[, 4])
colnames(ids) <- 'id'

ccolLinf <- c('blue', 'blue', 'blue', 'red', 'red', 'red', 'black', 'black', 'green', 'green', 'black', 'green')
ccolLinf <-  rep(ccolLinf, each = 5)

CHAN_NAMES <- rep(c('DAPI1', 'DAPI2', 'DAPI3', 'GABA', 'GAD2', 'Gephyrin', 'GluN1',
                'MBP', 'PSD95', 'synapsin', 'TdTomato', 'VGlut1'), each = 5)
colnames(naInf) <- paste0(CHAN_NAMES,"_", sprintf("%d",1:5))

## annotation ids in the BOSS are +1 from the ids in Forrest's gsheet.
#annoSizes <- read.csv('annotation_sizes_pixels.csv')
#annoSizes$id <- annoSizes$id - 1
#
#tmp <- merge(ids, annoSizes, by = "id", all.x = TRUE)

```



```{r}
snaLinf <- scale(naInf, center = TRUE, scale = TRUE)
pcInf <- princomp(snaLinf)
gaba <- as.factor(meta$gaba)
```

## LDA and QDA

Next, applying LDA and QDA iterating on the number of PCA dimension
included. 
```{r lda-gabaLinf}
ldaLinf <- foreach(x = 1:ncol(snaLinf)) %dopar% {
           ldatmp <- lda(gaba ~ pcInf$scores[, 1:x], CV = FALSE)
           ldatmp
}

qdaLinf <- foreach(x = 1:ncol(snaLinf)) %dopar% {
           qdatmp <- 
             tryCatch(qda(as.factor(gaba) ~ pcInf$scores[, 1:x], CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfLinf <- foreach(x = 1:ncol(snaLinf)) %dopar% {
           tmpdat <- data.table(gaba = gaba, pcInf$scores[, 1:x])
           rftmp <- randomForest(gaba ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

ll <- sapply(ldaLinf, function(x) sum(predict(x)$class != gaba)/length(gaba))
ql <- sapply(qdaLinf, function(x) sum(predict(x)$class != gaba)/length(gaba))
rl <- sapply(rfLinf,  function(x) sum(predict(x) != gaba)/length(gaba))
```


```{r plot-itLinf}
plot(x = 1:ncol(pcInf$scores), y = seq(0,max(ll,ql,rl),length = ncol(pcInf$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(ll, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(ql, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(rl, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(gaba == 1)/length(gaba), col = 'magenta', lty=4)
text(40,min(ql), label = paste("qda", min(round(ql, 3))), col = 'orange', pos = 4)
text(ncol(snaLinf)/2, min(ll), label = paste("lda", min(round(ll,3))), col = 'blue', pos = 1)
text(ncol(snaLinf)/3, min(rl), label = paste("rf", min(round(rl,3))), col = 'darkgreen')
text(ncol(snaLinf)/4, chance, label = "chance", col = 'magenta', pos = 3)
title("Run on L_infty data")
```


# MEDA run on $L_1$ data

```{r runAll-L1, eval = TRUE, echo = FALSE, include = FALSE}
set.seed(317)

w = 720
h = 720 

png("d1heat_L1.png", width = w, height = h)
p1 <- plot(d1heat(snaL1, ccol = ccolL1)) 
p1
dev.off()

png("mlocation_L1.png", width = 720, height = 480)
p1 <- plot(mlocation(naL1, ccol = ccolL1)) 
p1
dev.off()

png("cumulativeVariance_L1.png", width = w, height = h)
p1 <- plot(cumvar(snaL1)) 
p1
dev.off()

png("outliers_L1.png", width = w, height = h)
p1 <- plot(outliers(snaL1)) 
p1
dev.off()

png("cor_L1.png", width = w, height = h)
plot(medacor(snaL1, ccol = ccolL1)) 
dev.off()

png("pairhex_L1.png", width = 2*w, height = 2*h)
spair <- sample(ncol(snaL1), 15)
pairhex(snaL1[,spair])
dev.off()

png("hmcClassifications_L1.png", width = 2*w, height = 2*h)
hL1 <- hmc(snaL1, modelNames = c("VVI"), ccol = ccolL1)

cr <- viridis(max(hL1$dat$labels$col))
pairs(hL1$dat$data[, spair], pch = 19, cex = 0.5, col = cr[hL1$dat$labels$col])
dev.off()

png("dendrograms_L1.png", width = w, height = h)
plotDend(hL1)
dev.off()

png("stackMeans_L1.png", width = w, height = 2*h)
p1 <- stackM(hL1, ccol = ccolL1, depth = 3, centered = TRUE)
p1
dev.off()

png("clusterMeans_L1.png", width = w, height = 0.75*h)
p1 <- clusterMeans(hL1, ccol = ccolL1)
p1
dev.off()
```


## 1-d Heatmap
![](./d1heat_L1.png)

## Location meda_plots
![](./mlocation_L1.png)

## Outliers as given by randomForest
![](./outliers_L1.png)

## Correlation Matrix
![](./cor_L1.png)

## Cumulative Variance with Elbows
![](./cumulativeVariance_L1.png)

## Paired Hex-binned plot
![](./pairhex_L1.png)

## Hierarchical GMM Classifications
![](./hmcClassifications_L1.png)

## Hierarchical GMM Dendrogram
![](./dendrograms_L1.png)

## Stacked Means
![](./stackMeans_L1.png)

## Cluster Means
![](./clusterMeans_L1.png)




# MEDA on Annuli stats using $L_{\infty}$ norm.

```{r runAll-Linf, eval = TRUE, echo = FALSE, include = FALSE}
set.seed(317)

w = 720
h = 720 

png("d1heat_Linf.png", width = w, height = h)
p1 <- plot(d1heat(snaLinf, ccol = ccolLinf)) 
p1
dev.off()

png("mlocation_Linf.png", width = 720, height = 480)
p1 <- plot(mlocation(naInf, ccol = ccolLinf)) 
p1
dev.off()

png("cumulativeVariance_Linf.png", width = w, height = h)
p1 <- plot(cumvar(snaLinf)) 
p1
dev.off()

png("outliers_Linf.png", width = w, height = h)
p1 <- plot(outliers(snaLinf)) 
p1
dev.off()

png("cor_Linf.png", width = w, height = h)
plot(medacor(snaLinf, ccol = ccolLinf)) 
dev.off()

png("pairhex_Linf.png", width = 2*w, height = 2*h)
spairI <- sample(ncol(snaLinf), 15)
pairhex(snaLinf[,spairI])
dev.off()

png("hmcClassifications_Linf.png", width = 2*w, height = 2*h)
hLinf <- hmc(snaLinf, modelNames = c("VVI"), ccol = ccolLinf)

closestK(hLinf, K = 5, loc)
cr <- viridis(max(hLinf$dat$labels$col))
pairs(hLinf$dat$data[, spairI], pch = 19, cex = 0.5, col = cr[hLinf$dat$labels$col])
dev.off()

png("dendrograms_Linf.png", width = w, height = h)
plotDend(hLinf)
dev.off()

png("stackMeans_Linf.png", width = w, height = 2*h)
p1 <- stackM(hLinf, ccol = ccolLinf, depth = 3, centered = TRUE)
p1
dev.off()

png("clusterMeans_Linf.png", width = w, height = 0.75*h)
p1 <- clusterMeans(hLinf, ccol = ccolLinf)
p1
dev.off()
```


## 1-d Heatmap
![](./d1heat_Linf.png)

## Location meda_plots
![](./mlocation_Linf.png)

## Outliers as given by randomForest
![](./outliers_Linf.png)

## Correlation Matrix
![](./cor_Linf.png)

## Cumulative Variance with Elbows
![](./cumulativeVariance_Linf.png)

## Paired Hex-binned plot
![](./pairhex_Linf.png)

## Hierarchical GMM Classifications
![](./hmcClassifications_Linf.png)

## Hierarchical GMM Dendrogram
![](./dendrograms_Linf.png)

## Stacked Means
![](./stackMeans_Linf.png)

## Cluster Means
![](./clusterMeans_Linf.png)


# Subset only the gaba dimensions


```{r subGABA}
namesSub <- grep("GABA", names(naL1))
subGABA <- data.table(as.matrix(snaL1)[, namesSub])
pc1sub <- princomp(subGABA)
```

## LDA and QDA on gaba dimensions


```{r lda-qda-subGABA}
y <- as.factor(gaba)

ldaL1subGABA <- foreach(di = 1:ncol(subGABA)) %dopar% {
           x <- as.data.frame(pc1sub$scores[, 1:di])
           ldatmp <- lda(y ~ ., data = x, CV = FALSE)
           ldatmp
}

qdaL1subGABA <- foreach(di = 1:ncol(subGABA)) %dopar% {
           x <- as.data.frame(pc1sub$scores[, 1:di])
           qdatmp <- 
             tryCatch(qda(y ~ ., data = x, CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfL1subGABA <- foreach(di = 1:ncol(subGABA)) %dopar% {
           tmpdat <- data.table(gaba = gaba, pc1sub$scores[, 1:di])
           rftmp <- randomForest(gaba ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

#saveRDS(list(ldaL1subGABA, qdaL1subGABA, rfL1subGABA), file = "models_lda_qda_rf.rdat")

llsub <- sapply(ldaL1subGABA, function(x) sum(predict(x)$class != gaba)/length(gaba))
qlsub <- sapply(qdaL1subGABA[!is.na(qdaL1subGABA)], function(x) sum(predict(x)$class != gaba)/length(gaba))
rlsub <- sapply(rfL1subGABA,   function(x) sum(predict(x) != gaba)/length(gaba))
```

```{r plot-itL1subGABA}
plot(x = 1:ncol(pc1sub$scores), y = seq(0,max(ll,ql,rl),length = ncol(pc1sub$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(llsub, type = 'b', col = 'blue', pch = 20, cex = 1)
points(qlsub, type = 'b', col = 'orange', pch = 15, cex = 1)
points(rlsub, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 1)
abline(h = chance <- sum(gaba == 1)/length(gaba), col = 'magenta', lty=4)
text(which.min(qlsub),min(qlsub), label = paste("qda", min(round(qlsub, 3))), col = 'orange', pos = 4)
text(which.min(llsub), min(llsub), label = paste("lda", min(round(llsub,3))), col = 'blue', pos = 1)
text(which.min(rlsub), min(rlsub), label = paste("rf", min(round(rlsub,3))), col = 'darkgreen', pos = 3)
text(ncol(subGABA)/4, chance, label = "chance", col = 'magenta', pos = 3)
title("resubstitution error on GABA only dimensions.")
```




