---
title: "Annuli Stats followed by PCA on RORB"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    fig_height: 10
    fig_width: 10
    highlight: pygments
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 2
---
```{r knitOPTS, include=FALSE}
knitr::opts_chunk$set(cache = FALSE, dev = "png")
knitr::opts_chunk$set(engine.path = 
  list( 
      python = '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3'
      )
)
```

```{r render, eval=FALSE, echo=FALSE}
require(rmarkdown)
require(knitr)
rmarkdown::render("rorb_annuli_stats.Rmd"); system("open rorb_annuli_stats.html -a /Applications/Chrome.app")
```

```{r setup,include=FALSE,results='asis',message=FALSE,warning=FALSE, echo = FALSE}
# Library calls here.
require(rmarkdown)
require(NMF)
require(knitr)
require(MASS)
require(doMC)
require(foreach)
require(scales)
require(raster)
require(mgc)
require(googlesheets)
registerDoMC(4)
suppressMessages(require(meda))
```


## PCA on annuli stats using $L_1$ Norm

```{r start, eval = TRUE}
naL1 <- fread("rorb_annuli_stats_GoogleDoc.csv", header = FALSE)
cnames <- colnames(naL1)
meta <- fread("GoogleDocData.csv")
loc <- fread("GoogleDocData.csv")[, 1:3]
ids <- as.data.frame(read.csv("GoogleDocData.csv")[, 4])
colnames(ids) <- 'id'

ccolL1 <- c('blue', 'blue', 'blue', 'red', 'red', 'red', 'black', 'black', 'green', 'green', 'black', 'green')
ccolL1 <-  rep(ccolL1, each = 15)

CHAN_NAMES <- rep(c('DAPI1', 'DAPI2', 'DAPI3', 'GABA', 'GAD2', 'Gephyrin', 'GluN1',
                'MBP', 'PSD95', 'synapsin', 'TdTomato', 'VGlut1'), each = 15)
colnames(naL1) <- paste0(CHAN_NAMES,"_", sprintf("%02d",1:15))
```

```{r}
snaL1 <- scale(naL1, center = TRUE, scale = TRUE)
pc1 <- princomp(snaL1)
gaba <- as.factor(meta$gaba)
```

## LDA and QDA

Next, applying LDA and QDA iterating on the number of PCA dimension
included. 

```{r lda-gabaL1}
ldaL1 <- foreach(x = 1:ncol(snaL1)) %dopar% {
           ldatmp <- lda(gaba ~ pc1$scores[, 1:x], CV = FALSE)
           ldatmp
}

qdaL1 <- foreach(x = 1:ncol(snaL1)) %dopar% {
           qdatmp <- 
             tryCatch(qda(as.factor(gaba) ~ pc1$scores[, 1:x], CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfL1 <- foreach(x = 1:ncol(snaL1)) %dopar% {
           tmpdat <- data.table(gaba = gaba, pc1$scores[, 1:x])
           rftmp <- randomForest(gaba ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

ll <- sapply(ldaL1, function(x) sum(predict(x)$class != gaba)/length(gaba))
ql <- sapply(qdaL1[!is.na(qdaL1)], function(x) sum(predict(x)$class != gaba)/length(gaba))
rl <- sapply(rfL1,   function(x) sum(predict(x) != gaba)/length(gaba))
```

```{r plot-itL1}
plot(x = 1:ncol(pc1$scores), y = seq(0,max(ll,ql,rl),length = ncol(pc1$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(ll, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(ql, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(rl, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(gaba == 1)/length(gaba), col = 'magenta', lty=4)
text(40,min(ql), label = paste("qda", min(round(ql, 3))), col = 'orange', pos = 4)
text(ncol(snaL1)/2, min(ll), label = paste("lda", min(round(ll,3))), col = 'blue', pos = 1)
text(ncol(snaL1)/3, min(rl), label = paste("rf", min(round(rl,3))), col = 'darkgreen')
text(ncol(snaL1)/4, chance, label = "chance", col = 'magenta', pos = 3)
```





## PCA on annuli stats using $L_{\infty}$ Norm

```{r startInf, eval = TRUE}
naInf <- fread("rorb_annuli_stats_GoogleDocInf.csv", header = FALSE)
cnames <- colnames(naInf)
meta <- fread("GoogleDocData.csv")
loc <- fread("GoogleDocData.csv")[, 1:3]
ids <- as.data.frame(read.csv("GoogleDocData.csv")[, 4])
colnames(ids) <- 'id'

ccolLinf <- c('blue', 'blue', 'blue', 'red', 'red', 'red', 'black', 'black', 'green', 'green', 'black', 'green')
ccolLinf <-  rep(ccolLinf, each = 5)

CHAN_NAMES <- rep(c('DAPI1', 'DAPI2', 'DAPI3', 'GABA', 'GAD2', 'Gephyrin', 'GluN1',
                'MBP', 'PSD95', 'synapsin', 'TdTomato', 'VGlut1'), each = 5)
colnames(naInf) <- paste0(CHAN_NAMES,"_", sprintf("%d",1:5))

## annotation ids in the BOSS are +1 from the ids in Forrest's gsheet.
#annoSizes <- read.csv('annotation_sizes_pixels.csv')
#annoSizes$id <- annoSizes$id - 1
#
#tmp <- merge(ids, annoSizes, by = "id", all.x = TRUE)

```



```{r}
snaLinf <- scale(naInf, center = TRUE, scale = TRUE)
pcInf <- princomp(snaLinf)
gaba <- as.factor(meta$gaba)
```

## LDA and QDA

Next, applying LDA and QDA iterating on the number of PCA dimension
included. 
```{r lda-gabaLinf}
ldaLinf <- foreach(x = 1:ncol(snaLinf)) %dopar% {
           ldatmp <- lda(gaba ~ pcInf$scores[, 1:x], CV = FALSE)
           ldatmp
}

qdaLinf <- foreach(x = 1:ncol(snaLinf)) %dopar% {
           qdatmp <- 
             tryCatch(qda(as.factor(gaba) ~ pcInf$scores[, 1:x], CV = FALSE),
                      error=function(err) NA)
           qdatmp
}

rfLinf <- foreach(x = 1:ncol(snaLinf)) %dopar% {
           tmpdat <- data.table(gaba = gaba, pcInf$scores[, 1:x])
           rftmp <- randomForest(gaba ~ ., data = tmpdat, prox = TRUE)
           rftmp
}

ll <- sapply(ldaLinf, function(x) sum(predict(x)$class != gaba)/length(gaba))
ql <- sapply(qdaLinf, function(x) sum(predict(x)$class != gaba)/length(gaba))
rl <- sapply(rfLinf,  function(x) sum(predict(x) != gaba)/length(gaba))
```


```{r plot-itLinf}
plot(x = 1:ncol(pcInf$scores), y = seq(0,max(ll,ql,rl),length = ncol(pcInf$scores)), type = 'n', xlab = expression(hat(d)), ylab = "L")
points(ll, type = 'b', col = 'blue', pch = 20, cex = 0.5)
points(ql, type = 'b', col = 'orange', pch = 15, cex = 0.5)
points(rl, type = 'b', col = 'darkgreen', lty = 2, pch = 24, cex = 0.2)
abline(h = chance <- sum(gaba == 1)/length(gaba), col = 'magenta', lty=4)
text(40,min(ql), label = paste("qda", min(round(ql, 3))), col = 'orange', pos = 4)
text(ncol(snaLinf)/2, min(ll), label = paste("lda", min(round(ll,3))), col = 'blue', pos = 1)
text(ncol(snaLinf)/3, min(rl), label = paste("rf", min(round(rl,3))), col = 'darkgreen')
text(ncol(snaLinf)/4, chance, label = "chance", col = 'magenta', pos = 3)
```



```{r runAll-L1, eval = TRUE, echo = FALSE, include = FALSE}
set.seed(317)

w = 720
h = 720 

png("d1heat_L1.png", width = w, height = h)
p1 <- plot(d1heat(snaL1, ccol = ccolL1)) 
p1
dev.off()

png("mlocation_L1.png", width = 720, height = 480)
p1 <- plot(mlocation(naL1, ccol = ccolL1)) 
p1
dev.off()

png("cumulativeVariance_L1.png", width = w, height = h)
p1 <- plot(cumvar(snaL1)) 
p1
dev.off()

png("outliers_L1.png", width = w, height = h)
p1 <- plot(outliers(snaL1)) 
p1
dev.off()

png("cor_L1.png", width = w, height = h)
plot(medacor(snaL1, ccol = ccolL1)) 
dev.off()

png("pairhex_L1.png", width = 2*w, height = 2*h)
spair <- sample(ncol(snaL1), 15)
pairhex(snaL1[,spair])
dev.off()

png("hmcClassifications_L1.png", width = 2*w, height = 2*h)
hL1 <- hmc(snaL1, modelNames = c("VVI"), ccol = ccolL1)

cr <- viridis(max(hL1$dat$labels$col))
pairs(hL1$dat$data[, spair], pch = 19, cex = 0.5, col = cr[hL1$dat$labels$col])
dev.off()

png("dendrograms_L1.png", width = w, height = h)
plotDend(hL1)
dev.off()

png("stackMeans_L1.png", width = w, height = 2*h)
p1 <- stackM(hL1, ccol = ccolL1, depth = 3, centered = TRUE)
p1
dev.off()

png("clusterMeans_L1.png", width = w, height = 0.75*h)
p1 <- clusterMeans(hL1, ccol = ccolL1)
p1
dev.off()
```

# Results for $L_1$

## 1-d Heatmap
![](./d1heat_L1.png)

## Location meda_plots
![](./mlocation_L1.png)

## Outliers as given by randomForest
![](./outliers_L1.png)

## Correlation Matrix
![](./cor_L1.png)

## Cumulative Variance with Elbows
![](./cumulativeVariance_L1.png)

## Paired Hex-binned plot
![](./pairhex_L1.png)

## Hierarchical GMM Classifications
![](./hmcClassifications_L1.png)

## Hierarchical GMM Dendrogram
![](./dendrograms_L1.png)

## Stacked Means
![](./stackMeans_L1.png)

## Cluster Means
![](./clusterMeans_L1.png)




## MEDA on Annuli stats using $L_{\infty}$ norm.
```{r runAll-Linf, eval = TRUE, echo = FALSE, include = FALSE}
set.seed(317)

w = 720
h = 720 

png("d1heat_Linf.png", width = w, height = h)
p1 <- plot(d1heat(snaLinf, ccol = ccolLinf)) 
p1
dev.off()

png("mlocation_Linf.png", width = 720, height = 480)
p1 <- plot(mlocation(naInf, ccol = ccolLinf)) 
p1
dev.off()

png("cumulativeVariance_Linf.png", width = w, height = h)
p1 <- plot(cumvar(snaLinf)) 
p1
dev.off()

png("outliers_Linf.png", width = w, height = h)
p1 <- plot(outliers(snaLinf)) 
p1
dev.off()

png("cor_Linf.png", width = w, height = h)
plot(medacor(snaLinf, ccol = ccolLinf)) 
dev.off()

png("pairhex_Linf.png", width = 2*w, height = 2*h)
spairI <- sample(ncol(snaLinf), 15)
pairhex(snaLinf[,spairI])
dev.off()

png("hmcClassifications_Linf.png", width = 2*w, height = 2*h)
hLinf <- hmc(snaLinf, modelNames = c("VVI"), ccol = ccolLinf)

cr <- viridis(max(hLinf$dat$labels$col))
pairs(hLinf$dat$data[, spairI], pch = 19, cex = 0.5, col = cr[hLinf$dat$labels$col])
dev.off()

png("dendrograms_Linf.png", width = w, height = h)
plotDend(hLinf)
dev.off()

png("stackMeans_Linf.png", width = w, height = 2*h)
p1 <- stackM(hLinf, ccol = ccolLinf, depth = 3, centered = TRUE)
p1
dev.off()

png("clusterMeans_Linf.png", width = w, height = 0.75*h)
p1 <- clusterMeans(hLinf, ccol = ccolLinf)
p1
dev.off()
```


# Results for $L_{\infty}$

## 1-d Heatmap
![](./d1heat_Linf.png)

## Location meda_plots
![](./mlocation_Linf.png)

## Outliers as given by randomForest
![](./outliers_Linf.png)

## Correlation Matrix
![](./cor_Linf.png)

## Cumulative Variance with Elbows
![](./cumulativeVariance_Linf.png)

## Paired Hex-binned plot
![](./pairhex_Linf.png)

## Hierarchical GMM Classifications
![](./hmcClassifications_Linf.png)

## Hierarchical GMM Dendrogram
![](./dendrograms_Linf.png)

## Stacked Means
![](./stackMeans_Linf.png)

## Cluster Means
![](./clusterMeans_Linf.png)
