---
title: "Synaptome Statistics: Report 201703"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    fig_height: 5
    fig_width: 5
    highlight: pygments
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
---
```{r knitOPTS, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, dev = "png")
```

```{r render, eval=FALSE, echo=FALSE}
require(rmarkdown)
rm(list=ls()); 
rmarkdown::render("Notes201703.Rmd")
system("open Notes201703.html")
```

```{r setup,include=FALSE,results='asis',message=FALSE,warning=FALSE, echo = FALSE}
### Library calls here.
require(rmarkdown)
require(knitr)
suppressMessages(require(meda))
```

# Synaptome Statistics: Notes 

The following is a short report on the exploration of the Kristina15
(K15) and Weiler (W) datasets.  Putative synapse locations have been
detected in K15 with Forrest's synapse detection algorithm and in W with
Anish's synapse detection algorithm.  For each feature channel
(Synapsin, VGlut, psd95, etc.) an 11x11x11 cube is extracted around each
each putative synapse location and the voxel values are summed, creating
a feature vector of length (number of channels). This gives us an $n
\times d$ matrix, where the $n$ rows correspond to putative synapses and
the $d$ columns correspond to the summed immunoflorescence in each
channel.

## Clustering 

We have implemented our own Hierarchical Mclust function by augmenting
Mclust.  In the course of exploring we used the full suite of models
available in 
[mclustModelNames p. 88](https://cran.r-project.org/web/packages/mclust/mclust.pdf)

After looking through the BIC plots of each of the 11 models for each
node of the tree it seemed best to use the unconstrained model "VVV" =
ellipsoidal, varying volume, shape, and orientation. 

The first pass of BIC on K15 and W with 10,000 sample points, respectively, appear below and both show that
"VVV" is the best model when comparing for K = {1,2}.

[K15](http://docs.neurodata.io/meda/examples/Kristina15/bic317_size10000/bicK15Raw_Node.pdf) &
[W](http://docs.neurodata.io/meda/examples/Weiler/bic317_size10000/bicWRaw_Node.pdf)  
<img src="http://docs.neurodata.io/meda/examples/Kristina15/bic317_size10000/bicK15Raw_Node.pdf" alt="K15Node" style="width:350px;height:350px;" title = "K15 Node" type =application/pdf>
<img src="http://docs.neurodata.io/meda/examples/Weiler/bic317_size10000/bicWRaw_Node.pdf" alt="WNode" style="width:350px;height:350px;" title = "W Node" type=application/pdf>

Towards the bottom of the tree, where clusters are getting smaller "VVV"
tends to suggest against splitting the data. Looking through the
BIC plots for multiple explorations we also see that "VVV" is not very
bad when compared to the other models.  
These observations seem to justify our choice "VVV" for further use. 

[K15](http://docs.neurodata.io/meda/examples/Kristina15/bic317_size10000/bicK15Raw_Node222.pdf) &
[W](http://docs.neurodata.io/meda/examples/Weiler/bic317_size10000/bicWRaw_Node222.pdf)  
<img src="http://docs.neurodata.io/meda/examples/Kristina15/bic317_size10000/bicK15Raw_Node222.pdf" alt="HTML5 Icon" style="width:350px;height:350px;" title = "K15 Node222" type=application/pdf>
<img src="http://docs.neurodata.io/meda/examples/Weiler/bic317_size10000/bicWRaw_Node222.pdf" alt="HTML5 Icon" style="width:350px;height:350px;" title = "W Node222" type=application/pdf>

## Scaling 

We have looked at various transformations of the data: Raw, $log_{10}$, and
scaling between 0 and 1000. Full lab notebooks can be found 
[here](http://docs.neurodata.io/meda/) 

Below we have the clustering results from hierarchical GMM.  Each level is shown 
with the means of the features of each node given in color (purple -
low, orange - high).
Note that the 0-1000 results are the last in the triple of plots.

Below are our stacked level mean plots which show for each level in the
cluster tree (separated by black horizonal lines) the means accross each 
of the features (low - purple, high - orange).  


- [K15 Raw](http://docs.neurodata.io/meda/examples/Kristina15/figs/k15Raw_seed1234_size10000.png)
- [K15 Log_10](http://docs.neurodata.io/meda/examples/Kristina15/figs/k15Log_seed1234_size10000.png)
- [K15 0-1000](http://docs.neurodata.io/meda/examples/Kristina15/figs/k1501e3_seed1234_size10000.png)

![K15 Raw](http://docs.neurodata.io/meda/examples/Kristina15/figs/k15Raw_seed1234_size10000.png)
![K15 Log_10](http://docs.neurodata.io/meda/examples/Kristina15/figs/k15Log_seed1234_size10000.png)
![K15 0-1000](http://docs.neurodata.io/meda/examples/Kristina15/figs/k1501e3_seed1234_size10000.png)

Out of these three different methods of transforming the data we tend to
prefer the [0-1000] scaling. Empirically it seems to capture —
interestingly —
the differences in the feature categories (Excitatory - green, Inhibatory - red, 
Other - blue). The $log_{10}$ transform fails to reveal any clusters
that have significantly higher than average excitatory expression. 


## Stability:

When sampling points it seems that analysis on 10,000 points is more stable 
than analysis on 1,000 points. We have yet to come up with a way to
quantify this objectively. This instability is demonstrated in the
stacked level means plots below. Two different samples of size 1,000 were taken
and our hierarchical GMM was performed on each. 


```{r stability, echo = FALSE, include = FALSE}
## Kristina15 data
load('~/neurodata/synaptome-stats/Code/cleanDataWithAttributes.RData')
#set.seed(1234)
set.seed(74171)
ss <- sample(nrow(data01))
s <- list(1:1e3, 1001:2000, 2001:12000, 12001:22000)

data01 <- transformData(data01, "1e3")$d01e3
datk1 <- scale(data01[ss[s[[1]]], 1:24, with = FALSE], center = TRUE, scale = FALSE)
datk2 <- scale(data01[ss[s[[2]]], 1:24, with = FALSE], center = TRUE, scale = FALSE)
datK3 <- scale(data01[ss[s[[3]]], 1:24, with = FALSE], center = TRUE, scale = FALSE)
datK4 <- scale(data01[ss[s[[4]]], 1:24, with = FALSE], center = TRUE, scale = FALSE)

ccol3 <- c("#197300", "#197300", "#197300", "#197300", "#197300", "#197300", 
  "#197300", "#197300", "#197300", "#197300", "#197300", "#cc0000", 
  "#cc0000", "#cc0000", "#cc0000", "#cc0000", "#cc0000", "#0000cd", 
  "#0000cd", "#0000cd", "#0000cd", "#0000cd", "#0000cd", "#0000cd"
  )

## Weiler data
require(rhdf5)
#rhdf5::h5ls("~/neurodata/synaptome-stats/Code/Notebooks/Ex10R55_F0.h5")
datH5 <- rhdf5::h5read("~/neurodata/synaptome-stats/Code/Notebooks/Ex10R55_F0.h5",
                       name = "F0")
datW <- as.data.table(t(datH5[,,1]))
namesEx <- read.csv("~/neurodata/synaptome-stats/Code/Python/chan.csv", head=FALSE, stringsAsFactors = FALSE)[,1]
names(datW) <- as.vector(namesEx)

d <- c(3,26,1,25, 27:29)
d <- c(d,setdiff(1:29, d))
datEx <- datW[,d, with = FALSE]

ccolEx <- 
  c("#197300", "#197300", "#197300", "#cc0000", "#cc0000", "#cc0000", 
    "#cc0000", "#197300", "#0000cd", "#197300", "#197300", "#197300", 
    "#0000cd", "#0000cd", "#197300", "#cc0000", "#cc0000", "#cc0000", 
    "#197300", "#0000cd", "#197300", "#0000cd", "#0000cd", "#0000cd", 
    "#0000cd", "#0000cd", "#0000cd", "#0000cd", "#0000cd")

fac <- factor(ccolEx, levels = c("#197300", "#cc0000", "#0000cd"), 
       ordered = TRUE)

datEx <- as.data.table(datEx[, order(fac), with = FALSE])
ccolEx <- ccolEx[order(fac)]

set.seed(317)
sww <- sample(nrow(datEx))
swww <- list(1:1e3, 1001:2000, 2001:12000, 12001:22000)

datEx <- transformData(datEx, "1e3")$d01e3
datw1 <- scale(datEx[sww[swww[[1]]],], center = TRUE, scale = FALSE)
datw2 <- scale(datEx[sww[swww[[2]]],], center = TRUE, scale = FALSE)
datW3 <- scale(datEx[sww[swww[[3]]],], center = TRUE, scale = FALSE)
datW4 <- scale(datEx[sww[swww[[4]]],], center = TRUE, scale = FALSE)
```

```{r hmc, fig.show = "hide", echo = FALSE, include = FALSE, cache = TRUE}
hmck1 <- p.hmc(datk1, maxDim = 5, modelNames = c("VVV"))
hmck2 <- p.hmc(datk2, maxDim = 5, modelNames = c("VVV"))
hmcK3 <- p.hmc(datK3, maxDim = 5, modelNames = c("VVV"))
hmcK4 <- p.hmc(datK4, maxDim = 5, modelNames = c("VVV"))

hmcw1 <- p.hmc(datw1, maxDim = 5, modelNames = c("VVV"))
hmcw2 <- p.hmc(datw2, maxDim = 5, modelNames = c("VVV"))
hmcW3 <- p.hmc(datW3, maxDim = 5, modelNames = c("VVV"))
hmcW4 <- p.hmc(datW4, maxDim = 5, modelNames = c("VVV"))
```

```{r stack, echo = FALSE, cache = TRUE}
pk1 <- p.stackM(hmck1, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) + 
  ggtitle("K15 with 1,000 sample points")
pk2 <- p.stackM(hmck2, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("K15 with 1,000 sample points")
pk3 <- p.stackM(hmcK3, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("K15 with 10,000 sample points")
pk4 <- p.stackM(hmcK4, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("K15 with 10,000 sample points")

pw1 <- p.stackM(hmcw1, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("W with 1,000 sample points")
pw2 <- p.stackM(hmcw2, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("W with 1,000 sample points")
pw3 <- p.stackM(hmcW3, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("W with 1,000 sample points")
pw4 <- p.stackM(hmcW4, centered = TRUE, ccol = ccol3, maxDepth = 5, depth = 5) +
  ggtitle("W with 1,000 sample points")
```

```{r stack8, echo = FALSE, fig.width = 12, fig.height = 10}
grid.arrange(pk1,pk2,pk3,pk4, ncol = 2)
```

## Kristina15 versus Weiler

The cluster structure found in the Kristina15 dataset would seem to be
more of what we would expect to see. This is less true of the Weiler
dataset that we have explored thus far.  This could be due to the
differences in synapse detection algorithm, or the datasets themselves. 
We will explore this further.  Notice that the cluster splits in the 
Weiler dataset tend to be dominated by DAPI and do not look nearly as
interesting in terms of the feature categories as does the Kristina15
dataset.

```{r kvw, echo = FALSE, include = FALSE}
set.seed(135)
sk <- sample(nrow(data01))
sk1 <- sk[1:1e4]

set.seed(317)
sw <- sample(nrow(datEx))
sw1 <- sw[1:1e4]

k1 <- scale(data01[sk1, 1:24, with = FALSE], center = TRUE, scale = FALSE)
w1 <- scale(datEx[sw1,], center = TRUE, scale = FALSE)

hk <- p.hmc(k1, modelNames = c("VVV"), maxDepth = 7, maxDim = 8)
hw <- p.hmc(w1, modelNames = c("VVV"), maxDepth = 7, maxDim = 8)

plk <- p.stackM(hk, maxDepth = 5, ccol = ccol3, centered = TRUE)
plw <- p.stackM(hw, maxDepth = 5, ccol = ccolEx, centered = TRUE)
```

```{r kvwP, fig.width = 12, fig.height = 6, echo = FALSE}
grid.arrange(plk + ggtitle("Kristina15"), plw  + ggtitle("Weiler"), ncol = 2)
```

--- 
---
