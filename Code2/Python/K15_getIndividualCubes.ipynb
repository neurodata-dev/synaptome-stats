{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resultsVol_1: Getting data\n",
    "\n",
    "Anish ran synapse detection on the chessboard dataset and has provided locations of potential synapses.\n",
    "Here, we pull data from those locations and export it into a nice dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kristina15rscaled317samp5000_synaptograms11cubes5NN_test7.h5'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import ndio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.linalg\n",
    "from numpy import genfromtxt\n",
    "import ndio.remote.neurodata as neurodata\n",
    "import os\n",
    "import sys\n",
    "\n",
    "nd = neurodata(hostname = \"synaptomes.neurodata.io\")\n",
    "local = False\n",
    "\n",
    "TOKEN1 = \"kristina15\"##(sys.argv[1])##\"Ex10R55\"\n",
    "#INPUT = \"./LocationData/Ex12R75/resultVol_1.csv\"##(sys.argv[2])\n",
    "INPUT = \"K15F0_rscaled317samp5e3_hmc5NN.csv\" # Locations from meda hmc\n",
    "NAME = \"synaptograms\"##(sys.argv[3])\n",
    "\n",
    "bf = 5\n",
    "\n",
    "output = TOKEN1 + \"rscaled317samp5000_\" + NAME + \"11cubes5NN_test7\"+ \".h5\"\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile(\"/Users/JLP/neurodata/synaptome-stats/Code/Python/functions.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "public_tokens = nd.get_public_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN1 in public_tokens # Should *definitely* be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1826, 12986, 41]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = nd.get_image_size(TOKEN1)\n",
    "channels = nd.get_channels(TOKEN1)\n",
    "\n",
    "xGlobal = [0,size[0]]\n",
    "yGlobal = [0,size[1]]\n",
    "zGlobal = [0,size[2]]\n",
    "\n",
    "globalMaxs = [size[0], size[1], size[2]]\n",
    "globalMaxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chan = []\n",
    "for key in channels:\n",
    "    chan.append(key)\n",
    "del chan[3]\n",
    "del chan[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import resultsVol_1\n",
    "Import the location data from \"resultVol_1.csv\" making sure that each location is not too \n",
    "close to the boundary of the data and round to nearest integer.\n",
    "And that the points are far enough away from the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  400,  5723,     5],\n",
       "       [  776,  5935,    15],\n",
       "       [ 1152, 12900,     9],\n",
       "       [  907,  4126,    15],\n",
       "       [  562,  5968,    27],\n",
       "       [  739,  5644,    24],\n",
       "       [  260, 10960,    23],\n",
       "       [  246,  9453,    31],\n",
       "       [ 1011,  1946,    32],\n",
       "       [  241,  9051,    32],\n",
       "       [  645,  6565,    11],\n",
       "       [  265,  6733,    34],\n",
       "       [  910,  1011,    29],\n",
       "       [  961,  4994,    19],\n",
       "       [  348,  7560,    21],\n",
       "       [  155,  8274,     9],\n",
       "       [   84,  1749,    32],\n",
       "       [  768,  7957,    25],\n",
       "       [ 1337,  5763,    19],\n",
       "       [   48,  5346,    26],\n",
       "       [  291,  1776,    11],\n",
       "       [  920,  5499,    18],\n",
       "       [  363, 12876,    18],\n",
       "       [  150,  9935,    23],\n",
       "       [  393,  3639,    34],\n",
       "       [ 1197,  5988,    28],\n",
       "       [  707,  2376,    10],\n",
       "       [ 1232,  4329,    16],\n",
       "       [ 1251,  5659,    12],\n",
       "       [  510,  2590,    19],\n",
       "       [  616,  7436,     6],\n",
       "       [  937, 12562,     8],\n",
       "       [  203, 12174,    27],\n",
       "       [  191,  7098,    24],\n",
       "       [   51,  9368,    22],\n",
       "       [ 1242,  7253,    26],\n",
       "       [  504,  3813,    26],\n",
       "       [  987,  3103,    10],\n",
       "       [ 1035,  4429,    19],\n",
       "       [ 1242,  3755,    16]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = genfromtxt(INPUT, delimiter=',', skip_header = 1).tolist()\n",
    "\n",
    "L1 = []\n",
    "for i in range(len(loc)):\n",
    "    if inRange(loc[i], globalMaxs, bf):\n",
    "        L1.append(loc[i])\n",
    "        \n",
    "np.random.seed(317)\n",
    "## Subtract one to account for python indexing from 0\n",
    "LL = np.around(np.asarray(L1) - 1, decimals = 0).astype(int)\n",
    "L = LL\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xLocal = [0, max(L[:,0])]\n",
    "yLocal = [0, max(L[:,1])] \n",
    "zLocal = [0, max(L[:,2])] \n",
    "len(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 11x11x11 cube around each location \n",
    "### 11x11x11 cube is used for features F0-F3, with the buffer needed for features F4-F5\n",
    "then cast to vector of length 11^3 and output as an array dim = (n,1331)\n",
    "\n",
    "#### N.B. This does take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of  39\n",
      "1 out of  39\n",
      "2 out of  39\n",
      "3 out of  39\n",
      "4 out of  39\n",
      "5 out of  39\n",
      "6 out of  39\n",
      "7 out of  39\n",
      "8 out of  39\n",
      "9 out of  39\n",
      "10 out of  39\n",
      "11 out of  39\n",
      "12 out of  39\n",
      "13 out of  39\n",
      "14 out of  39\n",
      "15 out of  39\n",
      "16 out of  39\n",
      "17 out of  39\n",
      "18 out of  39\n",
      "19 out of  39\n",
      "20 out of  39\n",
      "21 out of  39\n",
      "22 out of  39\n",
      "23 out of  39\n",
      "24 out of  39\n",
      "25 out of  39\n",
      "26 out of  39\n",
      "27 out of  39\n",
      "28 out of  39\n",
      "29 out of  39\n",
      "30 out of  39\n",
      "31 out of  39\n",
      "32 out of  39\n",
      "33 out of  39\n",
      "34 out of  39\n",
      "35 out of  39\n",
      "36 out of  39\n",
      "37 out of  39\n",
      "38 out of  39\n",
      "39 out of  39\n"
     ]
    }
   ],
   "source": [
    "synCube = []\n",
    "for i in range(len(L)):\n",
    "    print i, \"out of \", len(L)-1\n",
    "    cubeCh = []\n",
    "    for ch in chan:\n",
    "        xLocal = L[i][0]\n",
    "        yLocal = L[i][1]\n",
    "        zLocal = L[i][2]\n",
    "        queryGlobal = { \n",
    "            'token': TOKEN1,\n",
    "            'channel': ch,\n",
    "            'x_start': xLocal - bf,\n",
    "            'x_stop': xLocal + bf +1,\n",
    "            'y_start': yLocal - bf,\n",
    "            'y_stop': yLocal + bf +1,\n",
    "            'z_start': zLocal - bf,\n",
    "            'z_stop': zLocal + bf + 1,\n",
    "            'resolution': 0   \n",
    "            }\n",
    "        \n",
    "        gg = nd.get_cutout(**queryGlobal)\n",
    "        cubeCh.append(gg)\n",
    "        out = np.asarray(cubeCh)\n",
    "    synCube.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CR1_2ndA',\n",
       " 'GluR2_2ndA',\n",
       " 'PV_1stA',\n",
       " 'VAChT_4thA',\n",
       " 'GABARa1_4thA',\n",
       " 'VGluT2_2ndA',\n",
       " 'tubulin_8thA',\n",
       " 'VGluT3_1stA',\n",
       " 'TH_5thA',\n",
       " 'VGluT1_3rdA',\n",
       " 'NR2B_9thA',\n",
       " 'VGluT1_8thA',\n",
       " 'synapsinR_7thA',\n",
       " 'GAD_6thA',\n",
       " 'VGAT_5thA',\n",
       " 'Synpod_3rdA',\n",
       " 'synapsinGP_5thA',\n",
       " 'psd_8thA',\n",
       " 'dapi_1stA',\n",
       " 'GABABR1_3rdA',\n",
       " 'NMDAR1_6thA',\n",
       " 'NOS_9thA',\n",
       " 'gephyrin_1stA']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columnDat = np.transpose(np.asarray(cols))\n",
    "columnNames = [str(key) for key in chan]\n",
    "columnNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5fOUT = h5py.File(output, 'a')\n",
    "#h5fOUT.create_dataset(TOKEN1, data=cols)\n",
    "h5fOUT.create_dataset(TOKEN1, data=np.transpose(synCube))\n",
    "h5fOUT.create_dataset('Locations', data=np.transpose(L))\n",
    "h5fOUT.create_dataset('Channels', data=columnNames)\n",
    "h5fOUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
