{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resultsVol_1: Getting data\n",
    "\n",
    "Anish ran synapse detection on the chessboard dataset and has provided locations of potential synapses.\n",
    "Here, we pull data from those locations and export it into a nice dataset for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kristina15rscaled317samp5000_synaptograms11cubes5NN_test3.h5'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import ndio\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.linalg\n",
    "from numpy import genfromtxt\n",
    "import ndio.remote.neurodata as neurodata\n",
    "import os\n",
    "import sys\n",
    "\n",
    "nd = neurodata(hostname = \"synaptomes.neurodata.io\")\n",
    "local = False\n",
    "\n",
    "TOKEN1 = \"kristina15\"##(sys.argv[1])##\"Ex10R55\"\n",
    "#INPUT = \"./LocationData/Ex12R75/resultVol_1.csv\"##(sys.argv[2])\n",
    "INPUT = \"K15F0_rscaled317samp5e3_hmc5NN.csv\" # Locations from meda hmc\n",
    "NAME = \"synaptograms\"##(sys.argv[3])\n",
    "\n",
    "bf = 5\n",
    "\n",
    "output = TOKEN1 + \"rscaled317samp5000_\" + NAME + \"11cubes5NN_test3\"+ \".h5\"\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile(\"/Users/JLP/neurodata/synaptome-stats/Code/Python/functions.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "public_tokens = nd.get_public_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN1 in public_tokens # Should *definitely* be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = nd.get_image_size(TOKEN1)\n",
    "channels = nd.get_channels(TOKEN1)\n",
    "\n",
    "xGlobal = [0,size[0]]\n",
    "yGlobal = [0,size[1]]\n",
    "zGlobal = [0,size[2]]\n",
    "\n",
    "globalMaxs = [size[0], size[1], size[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'CR1_2ndA',\n",
       " u'GluR2_2ndA',\n",
       " u'PV_1stA',\n",
       " u'VAChT_4thA',\n",
       " u'GABARa1_4thA',\n",
       " u'VGluT2_2ndA',\n",
       " u'tubulin_8thA',\n",
       " u'VGluT3_1stA',\n",
       " u'TH_5thA',\n",
       " u'VGluT1_3rdA',\n",
       " u'NR2B_9thA',\n",
       " u'VGluT1_8thA',\n",
       " u'synapsinR_7thA',\n",
       " u'GAD_6thA',\n",
       " u'VGAT_5thA',\n",
       " u'Synpod_3rdA',\n",
       " u'synapsinGP_5thA',\n",
       " u'psd_8thA',\n",
       " u'dapi_1stA',\n",
       " u'GABABR1_3rdA',\n",
       " u'NMDAR1_6thA',\n",
       " u'NOS_9thA',\n",
       " u'gephyrin_1stA']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chan = []\n",
    "for key in channels:\n",
    "    chan.append(key)\n",
    "del chan[3]\n",
    "del chan[-5]\n",
    "chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import resultsVol_1\n",
    "Import the location data from \"resultVol_1.csv\" making sure that each location is not too \n",
    "close to the boundary of the data and round to nearest integer.\n",
    "And that the points are far enough away from the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  401,  5724,     6],\n",
       "       [  777,  5936,    16],\n",
       "       [ 1153, 12901,    10],\n",
       "       [  908,  4127,    16],\n",
       "       [  563,  5969,    28],\n",
       "       [  740,  5645,    25],\n",
       "       [  261, 10961,    24],\n",
       "       [  247,  9454,    32],\n",
       "       [ 1012,  1947,    33],\n",
       "       [  242,  9052,    33],\n",
       "       [  646,  6566,    12],\n",
       "       [  266,  6734,    35],\n",
       "       [  911,  1012,    30],\n",
       "       [  962,  4995,    20],\n",
       "       [  349,  7561,    22],\n",
       "       [  156,  8275,    10],\n",
       "       [   85,  1750,    33],\n",
       "       [  769,  7958,    26],\n",
       "       [ 1338,  5764,    20],\n",
       "       [   49,  5347,    27],\n",
       "       [  292,  1777,    12],\n",
       "       [  921,  5500,    19],\n",
       "       [  364, 12877,    19],\n",
       "       [  151,  9936,    24],\n",
       "       [  394,  3640,    35],\n",
       "       [ 1198,  5989,    29],\n",
       "       [  708,  2377,    11],\n",
       "       [ 1233,  4330,    17],\n",
       "       [ 1252,  5660,    13],\n",
       "       [  511,  2591,    20],\n",
       "       [  617,  7437,     7],\n",
       "       [  938, 12563,     9],\n",
       "       [  204, 12175,    28],\n",
       "       [  192,  7099,    25],\n",
       "       [   52,  9369,    23],\n",
       "       [ 1243,  7254,    27],\n",
       "       [  505,  3814,    27],\n",
       "       [  988,  3104,    11],\n",
       "       [ 1036,  4430,    20],\n",
       "       [ 1243,  3756,    17]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = genfromtxt(INPUT, delimiter=',', skip_header = 1).tolist()\n",
    "\n",
    "L1 = []\n",
    "for i in range(len(loc)):\n",
    "    if inRange(loc[i], globalMaxs, bf):\n",
    "        L1.append(loc[i])\n",
    "        \n",
    "np.random.seed(317)\n",
    "LL = np.around(np.asarray(L1), decimals = 0).astype(int)\n",
    "#s1 = np.random.choice(LL.shape[0], 10, replace = False)\n",
    "L = LL\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xLocal = [0, max(L[:,0])]\n",
    "yLocal = [0, max(L[:,1])] \n",
    "zLocal = [0, max(L[:,2])] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 11x11x11 cube around each location \n",
    "### 11x11x11 cube is used for features F0-F3, with the buffer needed for features F4-F5\n",
    "then cast to vector of length 11^3 and output as an array dim = (n,1331)\n",
    "\n",
    "#### N.B. This does take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of  40\n",
      "1 out of  40\n",
      "2 out of  40\n",
      "3 out of  40\n",
      "4 out of  40\n",
      "5 out of  40\n",
      "6 out of  40\n",
      "7 out of  40\n",
      "8 out of  40\n",
      "9 out of  40\n",
      "10 out of  40\n",
      "11 out of  40\n",
      "12 out of  40\n",
      "13 out of  40\n",
      "14 out of  40\n",
      "15 out of  40\n",
      "16 out of  40\n",
      "17 out of  40\n"
     ]
    }
   ],
   "source": [
    "synCube = []\n",
    "for i in range(len(L)):\n",
    "    print i, \"out of \", len(L)\n",
    "    cubeCh = []\n",
    "    for ch in chan:\n",
    "        xLocal = L[i][0]\n",
    "        yLocal = L[i][1]\n",
    "        zLocal = L[i][2]\n",
    "        queryGlobal = { \n",
    "            'token': TOKEN1,\n",
    "            'channel': ch,\n",
    "            'x_start': xLocal - (bf+1),\n",
    "            'x_stop': xLocal + bf,\n",
    "            'y_start': yLocal - (bf +1),\n",
    "            'y_stop': yLocal + bf,\n",
    "            'z_start': zLocal - (bf +1),\n",
    "            'z_stop': zLocal + bf,\n",
    "            'resolution': 0   \n",
    "            }\n",
    "        \n",
    "        gg = nd.get_cutout(**queryGlobal)\n",
    "        cubeCh.append(gg)\n",
    "        out = np.asarray(cubeCh)\n",
    "    synCube.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synCube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CR1_2ndA',\n",
       " 'GluR2_2ndA',\n",
       " 'PV_1stA',\n",
       " 'VAChT_4thA',\n",
       " 'GABARa1_4thA',\n",
       " 'VGluT2_2ndA',\n",
       " 'tubulin_8thA',\n",
       " 'VGluT3_1stA',\n",
       " 'TH_5thA',\n",
       " 'VGluT1_3rdA',\n",
       " 'NR2B_9thA',\n",
       " 'VGluT1_8thA',\n",
       " 'synapsinR_7thA',\n",
       " 'GAD_6thA',\n",
       " 'VGAT_5thA',\n",
       " 'Synpod_3rdA',\n",
       " 'synapsinGP_5thA',\n",
       " 'psd_8thA',\n",
       " 'dapi_1stA',\n",
       " 'GABABR1_3rdA',\n",
       " 'NMDAR1_6thA',\n",
       " 'NOS_9thA',\n",
       " 'gephyrin_1stA']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columnDat = np.transpose(np.asarray(cols))\n",
    "columnNames = [str(key) for key in chan]\n",
    "columnNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5fOUT = h5py.File(output, 'w')\n",
    "#h5fOUT.create_dataset(TOKEN1, data=cols)\n",
    "h5fOUT.create_dataset(TOKEN1, data=np.transpose(synCube))\n",
    "h5fOUT.create_dataset('Locations', data=np.transpose(L))\n",
    "h5fOUT.create_dataset('Channels', data=columnNames)\n",
    "h5fOUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
